environment: staging

image:
  repository: repository
  tag: "1.0.0"
  pullPolicy: IfNotPresent

nodeSelector: {
  app_node_group: prosperi-staging
}

network:
  port: 2000
  containerTargetPort: 8000
  serviceEnabled: false

ingress:
  enabled: false
  class: alb
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/healthcheck-path: /healthcheck/
    alb.ingress.kubernetes.io/success-codes: '200'
    alb.ingress.kubernetes.io/certificate-arn: CERTIFICATE_ARN
    helm.sh/resource-policy: keep
  # Single domain configuration (backward compatible)
  domain: domain.com
  # Multiple domains configuration (uncomment and remove domain above to use)
  # domains:
  #   - app.example.com
  #   - api.example.com
  #   - app.example.org

serviceAccount:
  name: secrets-csi-sa
  annotations: { eks.amazonaws.com/role-arn: arn:aws:iam::account_id:role/role_name }

apps:
  - name: app
    resources:
      requests:
        memory: 96M
        cpu: 50m
    replicaCount: 1
    # workingDir: /app/src # optional, if you want to run the commands from one specific directory without executing cd command
    command: [ 'python' ]
    args: [ '-m', 'src.app' ]
    externalNlb: nlb-prosperi-services
    exposePort: true
    readinessProbe:
      httpGet:
        path: /health/
      initialDelaySeconds: 5
      periodSeconds: 5
    # Liveness probe configuration (optional)
    livenessProbe:
      httpGet:
        path: /health/
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
    # Startup probe configuration (optional) - useful for slow-starting containers
    startupProbe:
      httpGet:
        path: /health/
      initialDelaySeconds: 0
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 30
    # HPA configuration
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 5
      targetCPUUtilizationPercentage: 80
      targetMemoryUtilizationPercentage: 80
      # HPA behavior policies (optional) - prevents thrashing
      # Defaults are provided, you can override them here
      # scaleDownStabilizationWindowSeconds: 300
      # scaleDownPercent: 50
      # scaleDownPods: 1
      # scaleDownPeriodSeconds: 60
      # scaleUpStabilizationWindowSeconds: 0
      # scaleUpPercent: 100
      # scaleUpPods: 2
      # scaleUpPeriodSeconds: 15
      # Or provide custom behavior:
      # behavior:
      #   scaleDown:
      #     stabilizationWindowSeconds: 300
      #     policies:
      #     - type: Percent
      #       value: 50
      #       periodSeconds: 60
      #   scaleUp:
      #     stabilizationWindowSeconds: 0
      #     policies:
      #     - type: Percent
      #       value: 100
      #       periodSeconds: 15
    #    nodeSelector: {
    #      app_node_group: prosperi-staging
    #    }
#  - name: consumer
#    resources:
#      requests:
#        memory: "96M"
#        cpu: "0.05"
#    replicaCount: 1
#    command: [ "/bin/sh", "-c"]
#    args: [ "cd", "src", "&&", "python3", "-m", "consumer" ]
#    nodeSelector: {
#      app_node_group: prosperi-staging
#    }



jobs:
#  - name: migration
#    ttlSecondsAfterFinished: 10
#    restartPolicy: Never
#    resources:
#      requests:
#        memory: 96M
#        cpu: 50m
#    command: ['aerich', 'upgrade']
#    nodeSelector: {
#      app_node_group: prosperi-staging
#    }

sharedSecrets:
  awsSecretName: APP/ENVIRONMENT/shared # specify shared secret name explicitly
  envs:
    - name: GITHUB_TOKEN

secrets:
  awsSecretName: APP/ENVIRONMENT/SECRET_NAME # specify secret name explicitly
  envs:
    - name: DATABASE_URL
    - name: ENVIRONMENT
    - name: RABBITMQ_URL
    - name: REDIS_URL
    - name: SENTRY_DSN
